# Proyecto NYC Taxis

## Roles

### Data Analyst
Responsable de explorar, analizar e interpretar los datos para generar insights que respalden la toma de decisiones.

***Responsabilidades***
- Consultar y extraer datos desde diferentes fuentes.
- Realizar análisis exploratorio de datos (EDA).
- Generar reportes, dashboards y visualizaciones.
- Definir métricas clave de rendimiento (KPIs).
- Colaborar con stakeholders para traducir requerimientos de negocio en consultas analíticas.

| ![Imagen usuario](assets/img/user-image.png) | ![Imagen usuario](assets/img/user-image.png) |
|:--:|:--:|
| **Samuel Rangel** | **Francisco Hugo Lezik** |

### Data Engineer
Encargado de diseñar, construir y mantener la infraestructura de datos necesaria para la ingestión, procesamiento y almacenamiento de datos a gran escala.

***Responsabilidades***
- Diseñar y desarrollar pipelines de datos escalables y eficientes.
- Integrar múltiples fuentes de datos (ETL/ELT).
- Optimizar el rendimiento y la calidad de los datos.
- Asegurar la disponibilidad, integridad y seguridad de los datos.
- Monitorear y mantener la infraestructura en entornos on-premise o en la nube.

| ![Imagen usuario](assets/img/user-image.png) | ![Imagen usuario](assets/img/user-image.png) |
|:--:|:--:|
| **Luis Muñoz** | **Juan C. Ruiz Navarro** |

### ML Engineer
Responsable de implementar, desplegar y mantener modelos de machine learning en producción.

***Responsabilidades***
- Colaborar con Data Scientists para traducir modelos en prototipos productivos.
- Diseñar pipelines de machine learning automatizados.
- Desplegar modelos en entornos de producción (CI/CD).
- Monitorear el rendimiento y la precisión de los modelos en producción.
- Optimizar modelos para escalabilidad y eficiencia.

| ![Imagen usuario](assets/img/user-image.png) | ![Imagen usuario](assets/img/user-image.png) |
|:--:|:--:|
| **Jose Quispe** | **Sebastian Diaz** |

### Metodologia 
Adoptaremos el marco de trabajo ágil SCRUM como metodología para gestionar el proyecto o el equipo de trabajo. SCRUM se centra en la colaboración, la adaptabilidad y la entrega continua de valor a través de iteraciones cortas llamadas Sprints. Este proyecto esta dividido en 3 sprints con el fin de hacer un seguimiento detallado en cada fase.

***- Sprint 1***
Durante el primer Sprint del proyecto, se llevaran a cabo tareas clave para establecer una base sólida y organizada. Se creó un repositorio en GitHub para centralizar el control de versiones, y se definió el equipo de trabajo junto con los roles de cada miembro. Se implementó el stack tecnológico necesario para el desarrollo, y se realizó un análisis preliminar de la calidad de los datos para garantizar su fiabilidad. Además, se adoptó la metodología de trabajo tipo Scrum, complementada con un cronograma general en formato Gantt para gestionar los tiempos y las entregas. Se seleccionaron tres KPIs fundamentales que guiarán el proyecto, se documentó el alcance detallado de las actividades, y se realizó un análisis exploratorio de datos (EDA) para obtener los primeros insights clave. Estas actividades sentaron las bases para un desarrollo eficiente y orientado a resultados.

***- Sprint 2 ***
En el segundo sprint del proyecto, se enfocaran los esfuerzos en establecer una infraestructura de datos robusta y funcional. Se implementara un proceso completo de ETL (Extracción, Transformación y Carga) acompañado de un Pipeline automatizado que garantizara la eficiencia y repetibilidad del flujo de datos. Esto incluirá la validación exhaustiva de los datos para asegurar su calidad. Paralelamente, se diseñó y detalló un modelo y diagrama (ER) que sirvió como base para estructurar un Data Warehouse (DW) y un Data Lake (DL), consolidando el almacenamiento de datos. También y se creó un workflow detallado que documenta las tecnologías utilizadas. Finalmente, se realizó un análisis de datos de muestra y se presentó un MVP (Minimum Viable Product), que permitirá demostrar la viabilidad y utilidad del sistema diseñado. Este Sprint sentara las bases técnicas para escalar y optimizar el proyecto en las siguientes etapas.

***- Sprint 3 ***
En el tercer Sprint del proyecto, se avanzara significativamente en la integración de herramientas analíticas y en la documentación técnica. Se diseñara y desarrollara los respectivos dashboards interactivos y visualmente atractivos, priorizando la claridad en la presentación de información estratégica mediante gráficos, reportes y elementos visuales bien estructurados. Paralelamente, se trabajara en el desarrollo de un modelo de Machine Learning, que incluirá etapas de selección del modelo y diseño de las características más relevantes a través de un proceso de Feature Engineering, todo debidamente documentado. El modelo de machine learning sera llevado a producción, asegurando su despliegue mediante una solución accesible y funcional. Además, se elaborara un informe técnico que detalla el análisis realizado y los fundamentos detrás de las decisiones tomadas, lo que garantiza la transparencia y el entendimiento del proceso.